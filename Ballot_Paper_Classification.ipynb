{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ballot Paper Classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PzNRCS1pX6N",
        "colab_type": "text"
      },
      "source": [
        "# **A PyTorch Implementation of MobileNetV2**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This is a PyTorch implementation of MobileNetV2 architecture as described in paper [Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation.](https://arxiv.org/pdf/1801.04381.pdf)\n",
        "\n",
        "The big idea behind MobileNet is that convolutional layers, which are essential to computer vision tasks but are quite expensive to compute, can be replaced by so-called **depthwise separable convolutions**.\n",
        "\n",
        "**MobileNetV2** uses depthwise separable convolutions, but its main building block now looks like this:\n",
        "\n",
        "![MobileNetV2](https://machinethink.net/images/mobilenet-v2/ResidualBlock@2x.png)\n",
        "\n",
        "There are three convolutional layers in the block. The last two are the ones we already know: a depthwise convolution that filters the inputs, followed by a 1×1 pointwise convolution layer. However, this 1×1 layer now has a different job.\n",
        "\n",
        "In V2 the pointwise convolution makes the number of channels smaller. This is why this layer is now known as the projection layer — it projects data with a high number of dimensions (channels) into a tensor with a much lower number of dimensions.\n",
        "\n",
        "For example, the depthwise layer may work on a tensor with 144 channels, which the projection layer will then shrink down to only 24 channels. This kind of layer is also called a bottleneck layer because it reduces the amount of data that flows through the network. (This is where the “bottleneck residual block” gets its name from: the output of each block is a bottleneck.)\n",
        "\n",
        "The first layer is the new in the block. This is also a 1×1 convolution. Its purpose is to expand the number of channels in the data before it goes into the depthwise convolution. Hence, this expansion layer always has more output channels than input channels — it pretty much does the opposite of the projection layer.\n",
        "\n",
        "Exactly by how much the data gets expanded is given by the expansion factor. This is one of those hyperparameters for experimenting with different architecture tradeoffs. The default expansion factor is 6.\n",
        "\n",
        "For example, if there is a tensor with 24 channels going into a block, the expansion layer first converts this into a new tensor with 24 * 6 = 144 channels. Next, the depthwise convolution applies its filters to that 144-channel tensor. And finally, the projection layer projects the 144 filtered channels back to a smaller number, say 24 again.\n",
        "![alt text](https://machinethink.net/images/mobilenet-v2/ExpandProject@2x.png)\n",
        "So the input and the output of the block are low-dimensional tensors, while the filtering step that happens inside block is done on a high-dimensional tensor.\n",
        "\n",
        "The second new thing in MobileNet V2’s building block is the residual connection. This works just like in ResNet and exists to help with the flow of gradients through the network. (The residual connection is only used when the number of channels going into the block is the same as the number of channels coming out of it, which is not always the case as every few blocks the output channels are increased.)\n",
        "\n",
        "As usual, each layer has batch normalization and the activation function is ReLU6. However, the output of the projection layer does not have an activation function applied to it. Since this layer produces low-dimensional data, the authors of the paper found that using a non-linearity after this layer actually destroyed useful information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQH-fSCh6AW7",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries\n",
        "1. PyTorch & Torch Vision\n",
        "2. NumPy\n",
        "3. Pandas\n",
        "4. OS Module\n",
        "5. Pillow\n",
        "6. Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIPRiJUOo8ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp3XIVg86_QC",
        "colab_type": "code",
        "outputId": "b0b22b1e-d04d-4c9b-b8af-f735a693532f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mounting Google Drive in files directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Sur2oI7KMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking if device (GPU or CPU) is available and assigning to device variable\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOH8yQFX7Teb",
        "colab_type": "code",
        "outputId": "6671d9e3-6203-45ee-95aa-62632e0014d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSLgQ-BW7jC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Directory \"Test\"\n",
        "!mkdir Test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWdUIh11CqK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting Test.tar.gz (test dataset) from drive to Test direcotry\n",
        "\n",
        "!tar -xzf \"gdrive/My Drive/Colab Notebooks/datasets/ballotpaper/Test.tar-1.gz\" -C \"Test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmaocYdsFeA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Directory \"Train\"\n",
        "!mkdir Train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6IIo6ifMKUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting Train.tar.gz (Train dataset) from drive to Train directory\n",
        "\n",
        "!tar -xzf \"gdrive/My Drive/Colab Notebooks/datasets/ballotpaper/Train.tar.gz\" -C \"Train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXvuLrpkMPsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path of csv file which contains image name and respective image label\n",
        "train_csv_path=\"Train/testset.csv\"\n",
        "test_csv_path=\"Test/testset.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "109klXo2MS0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading csv contents using pandas\n",
        "# By default it converts into pandas' dataframe\n",
        "\n",
        "train_set=pd.read_csv(train_csv_path)\n",
        "test_set=pd.read_csv(test_csv_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RqZM1uxMVfX",
        "colab_type": "code",
        "outputId": "399ec992-fb74-465f-edf3-5e782dfae495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_set.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>600795.jpeg</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627152.jpeg</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119963.jpeg</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118264.jpeg</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199420.jpeg</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Data  Label\n",
              "0  600795.jpeg     10\n",
              "1  627152.jpeg     10\n",
              "2  119963.jpeg     10\n",
              "3  118264.jpeg     10\n",
              "4  199420.jpeg     10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7PJzyZGMY-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selection of 20% random Sample from train data for validation purpose\n",
        "val_set=train_set.sample(frac=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHYrlAg2McxV",
        "colab_type": "code",
        "outputId": "0b657fb0-4123-4624-fc42-73b6f857472b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "val_set.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5547</th>\n",
              "      <td>668468.jpeg</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3368</th>\n",
              "      <td>619973.jpeg</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>637986.jpeg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7112</th>\n",
              "      <td>617735.jpeg</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5827</th>\n",
              "      <td>257344.jpeg</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Data  Label\n",
              "5547  668468.jpeg     42\n",
              "3368  619973.jpeg     31\n",
              "615   637986.jpeg     23\n",
              "7112  617735.jpeg     38\n",
              "5827  257344.jpeg     29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwoiw7m-MhAR",
        "colab_type": "code",
        "outputId": "bd73bb37-ec2b-47f7-f751-3c6e4d716cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# Histogram Representation of Random Sample\n",
        "# Viewing if validation data is stratified or not\n",
        "\n",
        "classes = val_set[\"Label\"]\n",
        "plt.hist(classes)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([200., 208., 191., 177., 206., 190., 168., 200., 194., 186.]),\n",
              " array([ 0. ,  4.7,  9.4, 14.1, 18.8, 23.5, 28.2, 32.9, 37.6, 42.3, 47. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktS4/wfr5HyaIdxzQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSe0ra3BMkgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing the data from Train set that are taken for validation\n",
        "# to avoid duplication and overlapping of data\n",
        "train_set=train_set.drop(val_set.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhZB9DyiMr6h",
        "colab_type": "code",
        "outputId": "eb7fc9ce-1dea-483b-ce85-570f05f49e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# After Dropping the duplicate data, the new shape of train set\n",
        "train_set.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7680, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MchTa-lHMtrf",
        "colab_type": "code",
        "outputId": "4ecd75d2-d85c-4788-fc67-293efbb29adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking test data shape\n",
        "test_set.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2609, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4of8dVMMvBL",
        "colab_type": "code",
        "outputId": "4fc72add-cf8f-4990-afd2-257200bf34a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "# Histogram Representation of train set\n",
        "# Checking train set label's frequency\n",
        "classes = train_set[\"Label\"]\n",
        "plt.hist(classes)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1000., 1000., 1000.,  800., 1000., 1000.,  800., 1000., 1000.,\n",
              "        1000.]),\n",
              " array([ 0. ,  4.7,  9.4, 14.1, 18.8, 23.5, 28.2, 32.9, 37.6, 42.3, 47. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADkBJREFUeJzt3W+onnd9x/H3Z431z2Smfw6hJOlO\nh2FSxtQSukjHkHZzbZWlD7QobgYJ5Em31dWh0SdljoGFYVUYhWA6I4jaVVmDlklIK24PzEytU9tM\nmnXWJKRNtH/UibrM7x7cv65nMWnSc5+e257v+wXhXNfvuu77+p0rnLzPfd1/kqpCktTPr8x6ApKk\n2TAAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaWjXrCTybCy+8sObn52c9DUl6Qbnv\nvvu+V1VzZ9rvlzoA8/Pz7N+/f9bTkKQXlCSPnM1+XgKSpKYMgCQ1ZQAkqSkDIElNGQBJauqMAUhy\ne5JjSb61YOz8JHuSPDS+njfGk+SjSQ4m+UaSyxbcZsvY/6EkW56fb0eSdLbO5hHAx4GrTxrbDuyt\nqg3A3rEOcA2wYfzZBtwGk2AANwO/A1wO3Px0NCRJs3HGAFTVl4HHTxreDOway7uA6xaMf6ImvgKs\nTnIR8IfAnqp6vKqeAPbwi1GRJC2jxT4HsKaqjo7lR4E1Y3ktcGjBfofH2OnGJUkzMvU7gauqkizZ\n/yyfZBuTy0dcfPHFU93X/PYvLMWUdBa+88E3zuS4Hf+OZ3Wuoef5npXl+Hte7COAx8alHcbXY2P8\nCLB+wX7rxtjpxn9BVe2oqo1VtXFu7owfZSFJWqTFBmA38PQrebYAdy0Yf8d4NdAm4KlxqeiLwBuS\nnDee/H3DGJMkzcgZLwEl+RTweuDCJIeZvJrng8AdSbYCjwDXj93vBq4FDgI/Bt4JUFWPJ/lr4Ktj\nvw9U1clPLEuSltEZA1BVbzvNpqtOsW8BN5zmfm4Hbn9Os5MkPW98J7AkNWUAJKkpAyBJTRkASWrK\nAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVl\nACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoy\nAJLUlAGQpKamCkCSv0jyQJJvJflUkpckuSTJviQHk3wmyblj3xeP9YNj+/xSfAOSpMVZdACSrAX+\nHNhYVb8FnAO8FbgFuLWqXgk8AWwdN9kKPDHGbx37SZJmZNpLQKuAlyZZBbwMOApcCdw5tu8CrhvL\nm8c6Y/tVSTLl8SVJi7ToAFTVEeBvge8y+Yf/KeA+4MmqOjF2OwysHctrgUPjtifG/hcs9viSpOms\nWuwNk5zH5Lf6S4AngX8Arp52Qkm2AdsALr744mnvTstkfvsXZj2FNjzXWirTXAL6feA/q+p4Vf03\n8DngCmD1uCQEsA44MpaPAOsBxvZXAN8/+U6rakdVbayqjXNzc1NMT5L0bKYJwHeBTUleNq7lXwU8\nCNwLvHnsswW4ayzvHuuM7fdUVU1xfEnSFKZ5DmAfkydzvwZ8c9zXDuC9wE1JDjK5xr9z3GQncMEY\nvwnYPsW8JUlTWvRzAABVdTNw80nDDwOXn2LfnwBvmeZ4kqSl4zuBJakpAyBJTRkASWrKAEhSUwZA\nkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMg\nSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQ\npKYMgCQ1ZQAkqampApBkdZI7k/x7kgNJXpfk/CR7kjw0vp439k2SjyY5mOQbSS5bmm9BkrQY0z4C\n+AjwT1X1KuDVwAFgO7C3qjYAe8c6wDXAhvFnG3DblMeWJE1h0QFI8grg94CdAFX1s6p6EtgM7Bq7\n7QKuG8ubgU/UxFeA1UkuWvTMJUlTmeYRwCXAceDvk9yf5GNJfhVYU1VHxz6PAmvG8lrg0ILbHx5j\nkqQZmCYAq4DLgNuq6rXAf/HM5R4AqqqAei53mmRbkv1J9h8/fnyK6UmSns00ATgMHK6qfWP9TiZB\neOzpSzvj67Gx/QiwfsHt142x/6eqdlTVxqraODc3N8X0JEnPZtEBqKpHgUNJfnMMXQU8COwGtoyx\nLcBdY3k38I7xaqBNwFMLLhVJkpbZqilv/2fAJ5OcCzwMvJNJVO5IshV4BLh+7Hs3cC1wEPjx2FeS\nNCNTBaCqvg5sPMWmq06xbwE3THM8SdLS8Z3AktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMG\nQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkD\nIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKamjoASc5J\ncn+Sz4/1S5LsS3IwyWeSnDvGXzzWD47t89MeW5K0eEvxCOBG4MCC9VuAW6vqlcATwNYxvhV4Yozf\nOvaTJM3IVAFIsg54I/CxsR7gSuDOscsu4LqxvHmsM7ZfNfaXJM3AtI8APgy8B/j5WL8AeLKqToz1\nw8DasbwWOAQwtj819pckzcCiA5DkTcCxqrpvCedDkm1J9ifZf/z48aW8a0nSAtM8ArgC+KMk3wE+\nzeTSz0eA1UlWjX3WAUfG8hFgPcDY/grg+yffaVXtqKqNVbVxbm5uiulJkp7NogNQVe+rqnVVNQ+8\nFbinqt4O3Au8eey2BbhrLO8e64zt91RVLfb4kqTpPB/vA3gvcFOSg0yu8e8c4zuBC8b4TcD25+HY\nkqSztOrMu5xZVX0J+NJYfhi4/BT7/AR4y1IcT5I0Pd8JLElNGQBJasoASFJTBkCSmjIAktSUAZCk\npgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhS\nUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSp\nKQMgSU0tOgBJ1ie5N8mDSR5IcuMYPz/JniQPja/njfEk+WiSg0m+keSypfomJEnP3TSPAE4A766q\nS4FNwA1JLgW2A3uragOwd6wDXANsGH+2AbdNcWxJ0pQWHYCqOlpVXxvLPwQOAGuBzcCusdsu4Lqx\nvBn4RE18BVid5KJFz1ySNJUleQ4gyTzwWmAfsKaqjo5NjwJrxvJa4NCCmx0eYyff17Yk+5PsP378\n+FJMT5J0ClMHIMnLgc8C76qqHyzcVlUF1HO5v6raUVUbq2rj3NzctNOTJJ3GVAFI8iIm//h/sqo+\nN4Yfe/rSzvh6bIwfAdYvuPm6MSZJmoFpXgUUYCdwoKo+tGDTbmDLWN4C3LVg/B3j1UCbgKcWXCqS\nJC2zVVPc9grgT4BvJvn6GHs/8EHgjiRbgUeA68e2u4FrgYPAj4F3TnFsSdKUFh2AqvoXIKfZfNUp\n9i/ghsUeT5K0tHwnsCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMg\nSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQ\npKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkppY9AEmuTvLtJAeTbF/u40uSJpY1\nAEnOAf4OuAa4FHhbkkuXcw6SpInlfgRwOXCwqh6uqp8BnwY2L/McJEksfwDWAocWrB8eY5KkZbZq\n1hM4WZJtwLax+qMk357i7i4Evjf9rF6wun//4DkAzwG8AM9Bbpnq5r9+NjstdwCOAOsXrK8bY/+n\nqnYAO5biYEn2V9XGpbivF6Lu3z94DsBzAJ6D01nuS0BfBTYkuSTJucBbgd3LPAdJEsv8CKCqTiT5\nU+CLwDnA7VX1wHLOQZI0sezPAVTV3cDdy3S4JbmU9ALW/fsHzwF4DsBzcEqpqlnPQZI0A34UhCQ1\ntSID0PHjJpLcnuRYkm8tGDs/yZ4kD42v581yjs+nJOuT3JvkwSQPJLlxjHc6By9J8q9J/m2cg78a\n45ck2Td+Hj4zXoCxoiU5J8n9ST4/1tudg7Ox4gLQ+OMmPg5cfdLYdmBvVW0A9o71leoE8O6quhTY\nBNww/t47nYOfAldW1auB1wBXJ9kE3ALcWlWvBJ4Ats5wjsvlRuDAgvWO5+CMVlwAaPpxE1X1ZeDx\nk4Y3A7vG8i7gumWd1DKqqqNV9bWx/EMmP/xr6XUOqqp+NFZfNP4UcCVw5xhf0ecAIMk64I3Ax8Z6\naHYOztZKDIAfN/GMNVV1dCw/CqyZ5WSWS5J54LXAPpqdg3Hp4+vAMWAP8B/Ak1V1YuzS4efhw8B7\ngJ+P9Qvodw7OykoMgE6hJi/3WvEv+UrycuCzwLuq6gcLt3U4B1X1P1X1Gibvsr8ceNWMp7SskrwJ\nOFZV9816Li8Ev3SfBbQEzvhxE408luSiqjqa5CImvxWuWElexOQf/09W1efGcKtz8LSqejLJvcDr\ngNVJVo3fgFf6z8MVwB8luRZ4CfBrwEfodQ7O2kp8BODHTTxjN7BlLG8B7prhXJ5X4zrvTuBAVX1o\nwaZO52Auyeqx/FLgD5g8F3Iv8Oax24o+B1X1vqpaV1XzTH7276mqt9PoHDwXK/KNYKP+H+aZj5v4\nmxlP6XmX5FPA65l86uFjwM3APwJ3ABcDjwDXV9XJTxSvCEl+F/hn4Js8c+33/UyeB+hyDn6byROc\n5zD55e6OqvpAkt9g8mKI84H7gT+uqp/ObqbLI8nrgb+sqjd1PQdnsiIDIEk6s5V4CUiSdBYMgCQ1\nZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktTU/wJ5i6xQD4Cz+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVajPDKnMwUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Location of Images of Train & Test sets.\n",
        "TRAIN_DATA_PATH=\"Train/testset\"\n",
        "TEST_DATA_PATH=\"Test/testset\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOyfLKsHMyaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation\n",
        "# Some random strategy applied \n",
        "# Trying to make train data as worst as possible so it even can learn in worst case\n",
        "# Normalization metrics are taken from ImageNet documentation as specified those \n",
        "# are standard and generalized\n",
        "\n",
        "TRANSFORM_IMG_train = transforms.Compose([\n",
        "    transforms.Resize((500,385)),\n",
        "    torchvision.transforms.RandomRotation((-25,25)),\n",
        "    torchvision.transforms.ColorJitter(brightness=0.05,contrast=0.5, hue=.05, saturation=.05),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "\n",
        "TRANSFORM_IMG_test = transforms.Compose([\n",
        "    transforms.Resize((500,385)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225] )\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7phodGKMzsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class to load image and its label as tensor as per csv file information\n",
        "# Converting image to tensor using PIL.Image\n",
        "\n",
        "class Ballot_Data_Load(Dataset):\n",
        "    \n",
        "    def __init__(self, data_dir_path,pd_df, img_transform):\n",
        "        self.data_dir_path=data_dir_path\n",
        "        self.df=pd_df\n",
        "        self.img_transform=img_transform\n",
        "    \n",
        "    # Required for shuffling    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        df_row=self.df.iloc[index,:]\n",
        "        img_name=df_row[0]\n",
        "        img_path=os.path.join(self.data_dir_path,img_name)\n",
        "        image=Image.open(img_path)\n",
        "        image=self.img_transform(image)\n",
        "        label=df_row[1]\n",
        "        return (image,label)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8oiT7lqM1ZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Object of train and test set to load tensor data of image and label\n",
        "train_dataset=Ballot_Data_Load(TRAIN_DATA_PATH,train_set,TRANSFORM_IMG_train)\n",
        "\n",
        "val_dataset=Ballot_Data_Load(TRAIN_DATA_PATH,val_set,TRANSFORM_IMG_test)\n",
        "\n",
        "test_dataset=Ballot_Data_Load(TEST_DATA_PATH,test_set,TRANSFORM_IMG_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX75_JTeM21O",
        "colab_type": "code",
        "outputId": "b8cf941b-a0be-4a8a-b30e-e61112f54480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Checking the train dataset\n",
        "# 100th Image and its tensor\n",
        "train_dataset[100][0]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.9124, -1.9124, -1.9124,  ..., -1.9124, -1.9124, -1.9124],\n",
              "         [-1.9124, -1.9124, -1.9124,  ..., -1.9124, -1.9124, -1.9124],\n",
              "         [-1.9124, -1.9124, -1.9124,  ..., -1.9124, -1.9124, -1.9124],\n",
              "         ...,\n",
              "         [-1.9124, -1.9124, -1.9124,  ..., -1.9124, -1.9124, -1.9124],\n",
              "         [-1.9124, -1.9124, -1.9124,  ..., -1.9124, -1.9124, -1.9124],\n",
              "         [-1.9124, -1.9124, -1.9124,  ..., -1.9124, -1.9124, -1.9124]],\n",
              "\n",
              "        [[-1.8256, -1.8256, -1.8256,  ..., -1.8256, -1.8256, -1.8256],\n",
              "         [-1.8256, -1.8256, -1.8256,  ..., -1.8256, -1.8256, -1.8256],\n",
              "         [-1.8256, -1.8256, -1.8256,  ..., -1.8256, -1.8256, -1.8256],\n",
              "         ...,\n",
              "         [-1.8256, -1.8256, -1.8256,  ..., -1.8256, -1.8256, -1.8256],\n",
              "         [-1.8256, -1.8256, -1.8256,  ..., -1.8256, -1.8256, -1.8256],\n",
              "         [-1.8256, -1.8256, -1.8256,  ..., -1.8256, -1.8256, -1.8256]],\n",
              "\n",
              "        [[-1.5953, -1.5953, -1.5953,  ..., -1.5953, -1.5953, -1.5953],\n",
              "         [-1.5953, -1.5953, -1.5953,  ..., -1.5953, -1.5953, -1.5953],\n",
              "         [-1.5953, -1.5953, -1.5953,  ..., -1.5953, -1.5953, -1.5953],\n",
              "         ...,\n",
              "         [-1.5953, -1.5953, -1.5953,  ..., -1.5953, -1.5953, -1.5953],\n",
              "         [-1.5953, -1.5953, -1.5953,  ..., -1.5953, -1.5953, -1.5953],\n",
              "         [-1.5953, -1.5953, -1.5953,  ..., -1.5953, -1.5953, -1.5953]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbmsVkl_M4L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating iterator object of Dataloader for creating batchsize with shuffle and assigning 3 core\n",
        "# for multiprocessing\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,  num_workers=3)\n",
        "\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=16, shuffle=True,  num_workers=3)\n",
        "\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=16, shuffle=True,  num_workers=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA3BQY4LM5q3",
        "colab_type": "code",
        "outputId": "164c84bf-8356-4f21-e034-d5a4df3fe589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_loader"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f01825c77f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LceYZYLuM7Pp",
        "colab_type": "code",
        "outputId": "33b73353-8301-44ab-b8eb-f13d0f1342df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Checking iterator object of Dataloader class \n",
        "for i in train_data_loader:\n",
        "    print(i)\n",
        "    break"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
            "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
            "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
            "          ...,\n",
            "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
            "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
            "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665]],\n",
            "\n",
            "         [[-1.9832, -1.9832, -1.9832,  ..., -1.9832, -1.9832, -1.9832],\n",
            "          [-1.9832, -1.9832, -1.9832,  ..., -1.9832, -1.9832, -1.9832],\n",
            "          [-1.9832, -1.9832, -1.9832,  ..., -1.9832, -1.9832, -1.9832],\n",
            "          ...,\n",
            "          [-1.9832, -1.9832, -1.9832,  ..., -1.9832, -1.9832, -1.9832],\n",
            "          [-1.9832, -1.9832, -1.9832,  ..., -1.9832, -1.9832, -1.9832],\n",
            "          [-1.9832, -1.9832, -1.9832,  ..., -1.9832, -1.9832, -1.9832]],\n",
            "\n",
            "         [[-1.7522, -1.7522, -1.7522,  ..., -1.7522, -1.7522, -1.7522],\n",
            "          [-1.7522, -1.7522, -1.7522,  ..., -1.7522, -1.7522, -1.7522],\n",
            "          [-1.7522, -1.7522, -1.7522,  ..., -1.7522, -1.7522, -1.7522],\n",
            "          ...,\n",
            "          [-1.7522, -1.7522, -1.7522,  ..., -1.7522, -1.7522, -1.7522],\n",
            "          [-1.7522, -1.7522, -1.7522,  ..., -1.7522, -1.7522, -1.7522],\n",
            "          [-1.7522, -1.7522, -1.7522,  ..., -1.7522, -1.7522, -1.7522]]],\n",
            "\n",
            "\n",
            "        [[[-1.9638, -1.9638, -1.9638,  ..., -1.9638, -1.9638, -1.9638],\n",
            "          [-1.9638, -1.9638, -1.9638,  ..., -1.9638, -1.9638, -1.9638],\n",
            "          [-1.9638, -1.9638, -1.9638,  ..., -1.9638, -1.9638, -1.9638],\n",
            "          ...,\n",
            "          [-1.9638, -1.9638, -1.9638,  ..., -1.9638, -1.9638, -1.9638],\n",
            "          [-1.9638, -1.9638, -1.9638,  ..., -1.9638, -1.9638, -1.9638],\n",
            "          [-1.9638, -1.9638, -1.9638,  ..., -1.9638, -1.9638, -1.9638]],\n",
            "\n",
            "         [[-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782],\n",
            "          [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782],\n",
            "          [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782],\n",
            "          ...,\n",
            "          [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782],\n",
            "          [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782],\n",
            "          [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782]],\n",
            "\n",
            "         [[-1.6476, -1.6476, -1.6476,  ..., -1.6476, -1.6476, -1.6476],\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.6476, -1.6476, -1.6476],\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.6476, -1.6476, -1.6476],\n",
            "          ...,\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.6476, -1.6476, -1.6476],\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.6476, -1.6476, -1.6476],\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.6476, -1.6476, -1.6476]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
            "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
            "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
            "          ...,\n",
            "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
            "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
            "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
            "\n",
            "         [[-1.1078, -1.1078, -1.1078,  ..., -1.1078, -1.1078, -1.1078],\n",
            "          [-1.1078, -1.1078, -1.1078,  ..., -1.1078, -1.1078, -1.1078],\n",
            "          [-1.1078, -1.1078, -1.1078,  ..., -1.1078, -1.1078, -1.1078],\n",
            "          ...,\n",
            "          [-1.1078, -1.1078, -1.1078,  ..., -1.1078, -1.1078, -1.1078],\n",
            "          [-1.1078, -1.1078, -1.1078,  ..., -1.1078, -1.1078, -1.1078],\n",
            "          [-1.1078, -1.1078, -1.1078,  ..., -1.1078, -1.1078, -1.1078]],\n",
            "\n",
            "         [[-0.8807, -0.8807, -0.8807,  ..., -0.8807, -0.8807, -0.8807],\n",
            "          [-0.8807, -0.8807, -0.8807,  ..., -0.8807, -0.8807, -0.8807],\n",
            "          [-0.8807, -0.8807, -0.8807,  ..., -0.8807, -0.8807, -0.8807],\n",
            "          ...,\n",
            "          [-0.8807, -0.8807, -0.8807,  ..., -0.8807, -0.8807, -0.8807],\n",
            "          [-0.8807, -0.8807, -0.8807,  ..., -0.8807, -0.8807, -0.8807],\n",
            "          [-0.8807, -0.8807, -0.8807,  ..., -0.8807, -0.8807, -0.8807]]],\n",
            "\n",
            "\n",
            "        [[[-0.5767, -0.5767,  1.2899,  ..., -0.5767, -0.5767, -0.5767],\n",
            "          [-0.5767, -0.5767,  1.2899,  ...,  1.2899,  1.2899,  1.2899],\n",
            "          [-0.5767, -0.5767,  1.2899,  ...,  1.2899,  1.2899,  1.2899],\n",
            "          ...,\n",
            "          [ 1.2899,  1.2899,  1.2899,  ...,  1.2899, -0.5767, -0.5767],\n",
            "          [ 1.2899,  1.2899,  1.2899,  ...,  1.2899, -0.5767, -0.5767],\n",
            "          [-0.5767, -0.5767, -0.5767,  ...,  1.2899, -0.5767, -0.5767]],\n",
            "\n",
            "         [[-0.4601, -0.4601,  1.7108,  ..., -0.4601, -0.4601, -0.4601],\n",
            "          [-0.4601, -0.4601,  1.7108,  ...,  1.6933,  1.6933,  1.6933],\n",
            "          [-0.4601, -0.4601,  1.7108,  ...,  1.6933,  1.6933,  1.6933],\n",
            "          ...,\n",
            "          [ 1.6933,  1.6933,  1.6933,  ...,  1.6933, -0.4601, -0.4601],\n",
            "          [ 1.6933,  1.6933,  1.6933,  ...,  1.6933, -0.4601, -0.4601],\n",
            "          [-0.4601, -0.4601, -0.4601,  ...,  1.6933, -0.4601, -0.4601]],\n",
            "\n",
            "         [[-0.2358, -0.2358,  2.1346,  ..., -0.2358, -0.2358, -0.2358],\n",
            "          [-0.2358, -0.2358,  2.1346,  ...,  2.0823,  2.0823,  2.0823],\n",
            "          [-0.2358, -0.2358,  2.1346,  ...,  2.0823,  2.0823,  2.0823],\n",
            "          ...,\n",
            "          [ 2.0823,  2.0823,  2.0823,  ...,  2.1346, -0.2358, -0.2358],\n",
            "          [ 2.0823,  2.0823,  2.0823,  ...,  2.1346, -0.2358, -0.2358],\n",
            "          [-0.2358, -0.2358, -0.2358,  ...,  2.1346, -0.2358, -0.2358]]],\n",
            "\n",
            "\n",
            "        [[[-0.5253, -0.5253, -0.5253,  ..., -0.5253, -0.5253, -0.5253],\n",
            "          [-0.5253, -0.5253, -0.5253,  ..., -0.5253, -0.5253, -0.5253],\n",
            "          [-0.5253, -0.5253, -0.5253,  ..., -0.5253, -0.5253, -0.5253],\n",
            "          ...,\n",
            "          [-0.5253, -0.5253, -0.5253,  ..., -0.5253, -0.5253, -0.5253],\n",
            "          [-0.5253, -0.5253, -0.5253,  ..., -0.5253, -0.5253, -0.5253],\n",
            "          [-0.5253, -0.5253, -0.5253,  ..., -0.5253, -0.5253, -0.5253]],\n",
            "\n",
            "         [[-0.4076, -0.4076, -0.4076,  ..., -0.4076, -0.4076, -0.4076],\n",
            "          [-0.4076, -0.4076, -0.4076,  ..., -0.4076, -0.4076, -0.4076],\n",
            "          [-0.4076, -0.4076, -0.4076,  ..., -0.4076, -0.4076, -0.4076],\n",
            "          ...,\n",
            "          [-0.4076, -0.4076, -0.4076,  ..., -0.4076, -0.4076, -0.4076],\n",
            "          [-0.4076, -0.4076, -0.4076,  ..., -0.4076, -0.4076, -0.4076],\n",
            "          [-0.4076, -0.4076, -0.4076,  ..., -0.4076, -0.4076, -0.4076]],\n",
            "\n",
            "         [[-0.1835, -0.1835, -0.1835,  ..., -0.1835, -0.1835, -0.1835],\n",
            "          [-0.1835, -0.1835, -0.1835,  ..., -0.1835, -0.1835, -0.1835],\n",
            "          [-0.1835, -0.1835, -0.1835,  ..., -0.1835, -0.1835, -0.1835],\n",
            "          ...,\n",
            "          [-0.1835, -0.1835, -0.1835,  ..., -0.1835, -0.1835, -0.1835],\n",
            "          [-0.1835, -0.1835, -0.1835,  ..., -0.1835, -0.1835, -0.1835],\n",
            "          [-0.1835, -0.1835, -0.1835,  ..., -0.1835, -0.1835, -0.1835]]]]), tensor([30, 28,  7, 28, 22,  5,  8, 37, 41, 18, 28, 21, 12, 27,  7, 14])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN0QrkmnM9Li",
        "colab_type": "code",
        "outputId": "f8b4f85a-5e16-47ef-cb2b-f9343fdad777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here val_data_loader contains two field ,one  is tensor with 3 channel for 32 observation which is image data\n",
        "# next is label for respective 32 observation\n",
        "for i in val_data_loader:\n",
        "    print(i[0].shape)\n",
        "    print(i[1].shape)\n",
        "    print(i)\n",
        "    break"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 3, 500, 385])\n",
            "torch.Size([16])\n",
            "[tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.1462, 2.1462, 2.1462],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.1804, 2.1804, 2.1804],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2147, 2.2147, 2.2147],\n",
            "          ...,\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          ...,\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
            "\n",
            "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          ...,\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
            "\n",
            "\n",
            "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          ...,\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          ...,\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
            "\n",
            "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          ...,\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
            "\n",
            "\n",
            "        [[[2.2318, 2.1804, 2.1633,  ..., 2.2318, 2.2318, 2.2318],\n",
            "          [2.2318, 2.1804, 2.1633,  ..., 2.1804, 2.1804, 2.1804],\n",
            "          [2.2318, 2.1804, 2.1633,  ..., 2.1119, 2.1119, 2.1119],\n",
            "          ...,\n",
            "          [2.0263, 2.0263, 2.0263,  ..., 2.0948, 2.1975, 2.2489],\n",
            "          [2.1975, 2.1975, 2.1975,  ..., 2.0948, 2.1975, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.0948, 2.1975, 2.2489]],\n",
            "\n",
            "         [[2.4286, 2.3936, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.3936, 2.4286,  ..., 2.4111, 2.4111, 2.4111],\n",
            "          [2.4286, 2.3936, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          ...,\n",
            "          [2.3761, 2.3761, 2.3761,  ..., 2.3936, 2.4111, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286]],\n",
            "\n",
            "         [[2.5354, 2.5529, 2.6400,  ..., 2.5529, 2.5529, 2.5529],\n",
            "          [2.5354, 2.5529, 2.6400,  ..., 2.5703, 2.5703, 2.5703],\n",
            "          [2.5354, 2.5529, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          ...,\n",
            "          [2.6051, 2.6051, 2.6051,  ..., 2.6051, 2.5703, 2.5529],\n",
            "          [2.6226, 2.6226, 2.6226,  ..., 2.6051, 2.5703, 2.5529],\n",
            "          [2.5703, 2.5703, 2.5703,  ..., 2.6051, 2.5703, 2.5529]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          ...,\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          ...,\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
            "\n",
            "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          ...,\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
            "\n",
            "\n",
            "        [[[2.2318, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2318, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          ...,\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4111, 2.4111, 2.4111,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          ...,\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
            "\n",
            "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          ...,\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
            "\n",
            "\n",
            "        [[[2.2318, 2.2318, 2.2489,  ..., 2.2318, 2.2318, 2.2318],\n",
            "          [2.2318, 2.2318, 2.2489,  ..., 2.2147, 2.2147, 2.2147],\n",
            "          [2.2318, 2.2318, 2.2489,  ..., 2.2318, 2.2318, 2.2318],\n",
            "          ...,\n",
            "          [2.2318, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "         [[2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.3936, 2.3936],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.3761, 2.3761, 2.3761],\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          ...,\n",
            "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.4111, 2.4111, 2.4111,  ..., 2.4286, 2.4286, 2.4286],\n",
            "          [2.3936, 2.3936, 2.3936,  ..., 2.4286, 2.4286, 2.4286]],\n",
            "\n",
            "         [[2.6400, 2.6400, 2.6400,  ..., 2.6226, 2.6226, 2.6226],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.6051, 2.6051],\n",
            "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          ...,\n",
            "          [2.5877, 2.5877, 2.5877,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.5529, 2.5529, 2.5529,  ..., 2.6400, 2.6400, 2.6400],\n",
            "          [2.5529, 2.5529, 2.5529,  ..., 2.6400, 2.6400, 2.6400]]]]), tensor([37, 41, 41,  2,  8, 19, 23, 13,  8, 14, 45, 38, 28, 17,  5, 44])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3_Hn-oPM_0S",
        "colab_type": "code",
        "outputId": "572ea1b8-8b18-41cd-b87e-da5e04938f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Also iterator can be loaded, since DataLoader class create iterator it saves memory by loading\n",
        "# only the accessed instance at memory\n",
        "next(iter(test_data_loader))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           ...,\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
              " \n",
              "          [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           ...,\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
              " \n",
              "          [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           ...,\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
              " \n",
              " \n",
              "         [[[2.1804, 2.1804, 2.1804,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           [2.0948, 2.0948, 2.0948,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           [2.0605, 2.0605, 2.0605,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           ...,\n",
              "           [2.2318, 2.1804, 2.1633,  ..., 2.0263, 2.0263, 2.0777],\n",
              "           [2.2489, 2.1975, 2.1462,  ..., 2.1975, 2.1975, 2.1975],\n",
              "           [2.2489, 2.1975, 2.1462,  ..., 2.2489, 2.2489, 2.2489]],\n",
              " \n",
              "          [[2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           [2.4111, 2.4111, 2.4111,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           ...,\n",
              "           [2.4286, 2.3936, 2.4286,  ..., 2.3761, 2.3761, 2.4111],\n",
              "           [2.4286, 2.4111, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
              " \n",
              "          [[2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           ...,\n",
              "           [2.5354, 2.5529, 2.6400,  ..., 2.6051, 2.6051, 2.6226],\n",
              "           [2.5529, 2.5703, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
              "           [2.5529, 2.5703, 2.6226,  ..., 2.5703, 2.5703, 2.5703]]],\n",
              " \n",
              " \n",
              "         [[[2.2318, 2.1804, 2.1633,  ..., 2.2318, 2.2318, 2.2318],\n",
              "           [2.2318, 2.1804, 2.1633,  ..., 2.1804, 2.1804, 2.1804],\n",
              "           [2.2318, 2.1804, 2.1633,  ..., 2.1119, 2.1119, 2.1119],\n",
              "           ...,\n",
              "           [2.0263, 2.0263, 2.0263,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           [2.1975, 2.1975, 2.1975,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.0948, 2.1975, 2.2489]],\n",
              " \n",
              "          [[2.4286, 2.3936, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.3936, 2.4286,  ..., 2.4111, 2.4111, 2.4111],\n",
              "           [2.4286, 2.3936, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           ...,\n",
              "           [2.3761, 2.3761, 2.3761,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286]],\n",
              " \n",
              "          [[2.5354, 2.5529, 2.6400,  ..., 2.5529, 2.5529, 2.5529],\n",
              "           [2.5354, 2.5529, 2.6400,  ..., 2.5703, 2.5703, 2.5703],\n",
              "           [2.5354, 2.5529, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           ...,\n",
              "           [2.6051, 2.6051, 2.6051,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           [2.6226, 2.6226, 2.6226,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           [2.5703, 2.5703, 2.5703,  ..., 2.6051, 2.5703, 2.5529]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[2.1462, 2.1462, 2.1462,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.1804, 2.1804, 2.1804,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2147, 2.2147, 2.2147,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           ...,\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
              " \n",
              "          [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           ...,\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
              " \n",
              "          [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           ...,\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
              " \n",
              " \n",
              "         [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           ...,\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
              " \n",
              "          [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           ...,\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
              " \n",
              "          [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           ...,\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
              " \n",
              " \n",
              "         [[[2.1804, 2.1804, 2.1804,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           [2.0948, 2.0948, 2.0948,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           [2.0605, 2.0605, 2.0605,  ..., 2.0948, 2.1975, 2.2489],\n",
              "           ...,\n",
              "           [2.2318, 2.1804, 2.1633,  ..., 2.0263, 2.0263, 2.0777],\n",
              "           [2.2489, 2.1975, 2.1462,  ..., 2.1975, 2.1975, 2.1975],\n",
              "           [2.2489, 2.1975, 2.1462,  ..., 2.2489, 2.2489, 2.2489]],\n",
              " \n",
              "          [[2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           [2.4111, 2.4111, 2.4111,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4286],\n",
              "           ...,\n",
              "           [2.4286, 2.3936, 2.4286,  ..., 2.3761, 2.3761, 2.4111],\n",
              "           [2.4286, 2.4111, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
              " \n",
              "          [[2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           [2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.5703, 2.5529],\n",
              "           ...,\n",
              "           [2.5354, 2.5529, 2.6400,  ..., 2.6051, 2.6051, 2.6226],\n",
              "           [2.5529, 2.5703, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
              "           [2.5529, 2.5703, 2.6226,  ..., 2.5703, 2.5703, 2.5703]]]]),\n",
              " tensor([40, 40, 13, 22, 33, 37, 30, 47, 25, 29, 13, 37, 27, 47, 21, 24])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVKltKtZNCMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using mobilenet_v2 pretrained architecture to train model\n",
        "model=models.mobilenet_v2(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssN-ySrhND-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modifying Fully Connected layer of built-in architecture to fit for 48 class as our problem \n",
        "# is classification into 48 classes \n",
        "model.classifier=nn.Sequential(\n",
        "  nn.Dropout(p=0.2),\n",
        "  nn.Linear(in_features=1280, out_features=48, bias=True)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCq5DdfHNGhC",
        "colab_type": "code",
        "outputId": "9e9d5f10-80d0-41c9-951c-23a8b3a97cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Assigning model to Gpu\n",
        "model.to(device)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNReLU(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNReLU(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2)\n",
              "    (1): Linear(in_features=1280, out_features=48, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ6kPjuXNKgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining epochs,loss and optimizer for training\n",
        "epochs = 10\n",
        "losses = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff_PcUh7Nh0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate Loss and Accuracy\n",
        "# This function is executed after every epoch completion,loss and accuracy are returned\n",
        "# Model must be switched to evaluation mode,to stop backtracking of gradient and \n",
        "# to disable droupout and batchnormalaization\n",
        "def evaluation_test(some_test):\n",
        "  model.eval()\n",
        "  total_loss=0\n",
        "  total_correct=0\n",
        "  \n",
        "  for i,(img,lbl) in enumerate(some_test):\n",
        "    \n",
        "    correct=0\n",
        "    \n",
        "    img=img.to(device)\n",
        "    lbl=lbl.to(device)\n",
        "    \n",
        "    test_forward = model.forward(img)\n",
        "    test_loss = losses(test_forward,lbl).item()\n",
        "    total_loss += test_loss\n",
        "    \n",
        "    max_val, predict_class = torch.max(test_forward.data, 1)\n",
        "    correct=(predict_class == lbl).sum().item()/len(lbl)\n",
        "    total_correct += correct\n",
        "    \n",
        "  return (total_loss/len(some_test) , (total_correct/len(some_test)*100))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tg23Fe6Nqup",
        "colab_type": "code",
        "outputId": "706394fa-b1b5-4cf2-f5d8-63fdd50f6b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.train()\n",
        "info_all=[]\n",
        "for epoch in range(epochs):\n",
        "  train_correct=0\n",
        "  for i, (images, labels) in enumerate(train_data_loader):\n",
        "\n",
        "\n",
        "    correct=0\n",
        "    # Clear the gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Assigning data and labels to device\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    # Forward propagation \n",
        "    outputs = model.forward(images)      \n",
        "\n",
        "\n",
        "    # Calculating loss with softmax to obtain cross entropy loss\n",
        "    loss = losses(outputs, labels)\n",
        "\n",
        "    # Backward propation\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating gradients\n",
        "    optimizer.step()\n",
        "\n",
        "  \n",
        "  # Looking for loss and accuracy in entire validation set and Train set\n",
        "  train_loss,train_acc = evaluation_test(train_data_loader)\n",
        "  val_loss,val_acc = evaluation_test(val_data_loader)\n",
        "\n",
        "  # Creating a list with info of training and validation,loss and accuracy for each epoch\n",
        "  # useful for plotting the curve of epoch vs trainingloss/training accuracy\n",
        " \n",
        "  for_plot={\"epoch\":epoch+1,\"train_loss\":train_loss,\"train_accuracy\":train_acc,\n",
        "            \"val_loss\":val_loss,\"val_accuracy\":val_acc}\n",
        "  info_all.append(for_plot) \n",
        "  \n",
        "  # Switching back train mode,as on evaluation of loss & accuracy, it was\n",
        "  # switched to evaluation mode\n",
        "  model.train()\n",
        "  print('Epoch [{}/{}], TrainingLoss: {:.4f}, TrainingAccuracy: {:.2f}%,ValLoss:{:.4f},ValAccuracy:{:.2f}%'\n",
        "    .format(epoch + 1, epochs,train_loss,train_acc,val_loss,val_acc))#Train the model\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], TrainingLoss: 0.0804, TrainingAccuracy: 99.68%,ValLoss:0.0754,ValAccuracy:99.43%\n",
            "Epoch [2/10], TrainingLoss: 0.0159, TrainingAccuracy: 99.91%,ValLoss:0.0116,ValAccuracy:99.90%\n",
            "Epoch [3/10], TrainingLoss: 0.0077, TrainingAccuracy: 99.94%,ValLoss:0.0110,ValAccuracy:99.84%\n",
            "Epoch [4/10], TrainingLoss: 0.0048, TrainingAccuracy: 99.98%,ValLoss:0.0024,ValAccuracy:100.00%\n",
            "Epoch [5/10], TrainingLoss: 0.0052, TrainingAccuracy: 99.93%,ValLoss:0.0027,ValAccuracy:99.90%\n",
            "Epoch [6/10], TrainingLoss: 0.0148, TrainingAccuracy: 99.77%,ValLoss:0.0200,ValAccuracy:99.64%\n",
            "Epoch [7/10], TrainingLoss: 0.0017, TrainingAccuracy: 100.00%,ValLoss:0.0013,ValAccuracy:99.95%\n",
            "Epoch [8/10], TrainingLoss: 0.0015, TrainingAccuracy: 99.99%,ValLoss:0.0003,ValAccuracy:100.00%\n",
            "Epoch [9/10], TrainingLoss: 0.0062, TrainingAccuracy: 99.96%,ValLoss:0.0011,ValAccuracy:100.00%\n",
            "Epoch [10/10], TrainingLoss: 0.0101, TrainingAccuracy: 99.84%,ValLoss:0.0043,ValAccuracy:100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1YL_w_5Nsji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a checkpoint dictionary, saving model and its state and optimizer state as well.\n",
        "# Saving dictionary to file , extension .pth,.pt,.pkl\n",
        "checkpoint = {'model': model,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swE6_kiQiIzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading saved model state to my_model\n",
        "# Creating model from saved state and switching it to evalulation mode for inference\n",
        "def load_checkpoint(model_path):\n",
        "  checkpoint=torch.load(model_path)\n",
        "  model=checkpoint[\"model\"]\n",
        "  \n",
        "  model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "  \n",
        "  for parameter in model.parameters():\n",
        "    parameter.requires_grad=False\n",
        "\n",
        "  model.eval()\n",
        "  return model\n",
        "\n",
        "my_model=load_checkpoint(\"checkpoint.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A768ZjX5iRHB",
        "colab_type": "code",
        "outputId": "be16da4f-5a3a-4ca1-d907-2e3384201db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "my_model.to(device)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNReLU(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNReLU(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2)\n",
              "    (1): Linear(in_features=1280, out_features=48, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs7pWAQ9iSrB",
        "colab_type": "code",
        "outputId": "1f986dc6-15fa-4bc4-d8bc-3d91e6426956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Test set accuracy\n",
        "correct=0\n",
        "for i,(imag,label) in enumerate(test_data_loader):\n",
        "  image=imag.to(device)\n",
        "  label=label.to(device)\n",
        "  output=my_model.forward(image)\n",
        "  max_val,prediction=torch.max(output.data,1)\n",
        "  correct+=(((prediction==label).sum().item())/len(label))\n",
        "print(correct/len(test_data_loader)*100)\n",
        "  "
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbG8FnnUiUX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting information of training and val set from info_all list of dict\n",
        "# It contain trains and test loss/accuracy for each epoch\n",
        "train_loss=[]\n",
        "train_acc=[]\n",
        "val_loss=[]\n",
        "val_acc=[]\n",
        "for i in info_all:\n",
        "  val_loss.append(i[\"val_loss\"])\n",
        "  val_acc.append(i[\"val_accuracy\"])\n",
        "  train_loss.append(i[\"train_loss\"])\n",
        "  train_acc.append(i[\"train_accuracy\"])\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRDOlPr4iaZr",
        "colab_type": "code",
        "outputId": "d10f3500-2da5-4bb3-bb79-b9c97d31153d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# Graph Showing epoch vs loss. \n",
        "plt.figure(figsize=(8,5))\n",
        "plt.title(\"epoch vs loss curve\")\n",
        "plt.plot(range(1,11),val_loss,label=\"val_set\")\n",
        "plt.plot(range(1,11),train_loss,label=\"train_set\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFNCAYAAAAHGMa6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9mZmZjnnZG9mZpZz/wd/+qlkCBtKxQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-j5_kXsibC4",
        "colab_type": "code",
        "outputId": "b66325f4-0f38-488e-8b47-b205f2d59c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# Graph showing epoch vs Accuracy\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.title(\"epoch vs Accuracy curve\")\n",
        "plt.plot(range(1,11),val_acc,label=\"val_set\")\n",
        "plt.plot(range(1,11),train_acc,label=\"train_set\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAFNCAYAAACZlLzrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngJmZWY36N6kHyv8VOyROAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrQKa1EyidB_",
        "colab_type": "code",
        "outputId": "85193bd7-6d02-45b6-e273-6a396f4d7eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(my_model,input_size=(3,500,385))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 250, 193]             864\n",
            "       BatchNorm2d-2         [-1, 32, 250, 193]              64\n",
            "             ReLU6-3         [-1, 32, 250, 193]               0\n",
            "            Conv2d-4         [-1, 32, 250, 193]             288\n",
            "       BatchNorm2d-5         [-1, 32, 250, 193]              64\n",
            "             ReLU6-6         [-1, 32, 250, 193]               0\n",
            "            Conv2d-7         [-1, 16, 250, 193]             512\n",
            "       BatchNorm2d-8         [-1, 16, 250, 193]              32\n",
            "  InvertedResidual-9         [-1, 16, 250, 193]               0\n",
            "           Conv2d-10         [-1, 96, 250, 193]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 250, 193]             192\n",
            "            ReLU6-12         [-1, 96, 250, 193]               0\n",
            "           Conv2d-13          [-1, 96, 125, 97]             864\n",
            "      BatchNorm2d-14          [-1, 96, 125, 97]             192\n",
            "            ReLU6-15          [-1, 96, 125, 97]               0\n",
            "           Conv2d-16          [-1, 24, 125, 97]           2,304\n",
            "      BatchNorm2d-17          [-1, 24, 125, 97]              48\n",
            " InvertedResidual-18          [-1, 24, 125, 97]               0\n",
            "           Conv2d-19         [-1, 144, 125, 97]           3,456\n",
            "      BatchNorm2d-20         [-1, 144, 125, 97]             288\n",
            "            ReLU6-21         [-1, 144, 125, 97]               0\n",
            "           Conv2d-22         [-1, 144, 125, 97]           1,296\n",
            "      BatchNorm2d-23         [-1, 144, 125, 97]             288\n",
            "            ReLU6-24         [-1, 144, 125, 97]               0\n",
            "           Conv2d-25          [-1, 24, 125, 97]           3,456\n",
            "      BatchNorm2d-26          [-1, 24, 125, 97]              48\n",
            " InvertedResidual-27          [-1, 24, 125, 97]               0\n",
            "           Conv2d-28         [-1, 144, 125, 97]           3,456\n",
            "      BatchNorm2d-29         [-1, 144, 125, 97]             288\n",
            "            ReLU6-30         [-1, 144, 125, 97]               0\n",
            "           Conv2d-31          [-1, 144, 63, 49]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 63, 49]             288\n",
            "            ReLU6-33          [-1, 144, 63, 49]               0\n",
            "           Conv2d-34           [-1, 32, 63, 49]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 63, 49]              64\n",
            " InvertedResidual-36           [-1, 32, 63, 49]               0\n",
            "           Conv2d-37          [-1, 192, 63, 49]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 63, 49]             384\n",
            "            ReLU6-39          [-1, 192, 63, 49]               0\n",
            "           Conv2d-40          [-1, 192, 63, 49]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 63, 49]             384\n",
            "            ReLU6-42          [-1, 192, 63, 49]               0\n",
            "           Conv2d-43           [-1, 32, 63, 49]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 63, 49]              64\n",
            " InvertedResidual-45           [-1, 32, 63, 49]               0\n",
            "           Conv2d-46          [-1, 192, 63, 49]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 63, 49]             384\n",
            "            ReLU6-48          [-1, 192, 63, 49]               0\n",
            "           Conv2d-49          [-1, 192, 63, 49]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 63, 49]             384\n",
            "            ReLU6-51          [-1, 192, 63, 49]               0\n",
            "           Conv2d-52           [-1, 32, 63, 49]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 63, 49]              64\n",
            " InvertedResidual-54           [-1, 32, 63, 49]               0\n",
            "           Conv2d-55          [-1, 192, 63, 49]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 63, 49]             384\n",
            "            ReLU6-57          [-1, 192, 63, 49]               0\n",
            "           Conv2d-58          [-1, 192, 32, 25]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 32, 25]             384\n",
            "            ReLU6-60          [-1, 192, 32, 25]               0\n",
            "           Conv2d-61           [-1, 64, 32, 25]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 32, 25]             128\n",
            " InvertedResidual-63           [-1, 64, 32, 25]               0\n",
            "           Conv2d-64          [-1, 384, 32, 25]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 32, 25]             768\n",
            "            ReLU6-66          [-1, 384, 32, 25]               0\n",
            "           Conv2d-67          [-1, 384, 32, 25]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 32, 25]             768\n",
            "            ReLU6-69          [-1, 384, 32, 25]               0\n",
            "           Conv2d-70           [-1, 64, 32, 25]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 32, 25]             128\n",
            " InvertedResidual-72           [-1, 64, 32, 25]               0\n",
            "           Conv2d-73          [-1, 384, 32, 25]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 32, 25]             768\n",
            "            ReLU6-75          [-1, 384, 32, 25]               0\n",
            "           Conv2d-76          [-1, 384, 32, 25]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 32, 25]             768\n",
            "            ReLU6-78          [-1, 384, 32, 25]               0\n",
            "           Conv2d-79           [-1, 64, 32, 25]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 32, 25]             128\n",
            " InvertedResidual-81           [-1, 64, 32, 25]               0\n",
            "           Conv2d-82          [-1, 384, 32, 25]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 32, 25]             768\n",
            "            ReLU6-84          [-1, 384, 32, 25]               0\n",
            "           Conv2d-85          [-1, 384, 32, 25]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 32, 25]             768\n",
            "            ReLU6-87          [-1, 384, 32, 25]               0\n",
            "           Conv2d-88           [-1, 64, 32, 25]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 32, 25]             128\n",
            " InvertedResidual-90           [-1, 64, 32, 25]               0\n",
            "           Conv2d-91          [-1, 384, 32, 25]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 32, 25]             768\n",
            "            ReLU6-93          [-1, 384, 32, 25]               0\n",
            "           Conv2d-94          [-1, 384, 32, 25]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 32, 25]             768\n",
            "            ReLU6-96          [-1, 384, 32, 25]               0\n",
            "           Conv2d-97           [-1, 96, 32, 25]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 32, 25]             192\n",
            " InvertedResidual-99           [-1, 96, 32, 25]               0\n",
            "          Conv2d-100          [-1, 576, 32, 25]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 32, 25]           1,152\n",
            "           ReLU6-102          [-1, 576, 32, 25]               0\n",
            "          Conv2d-103          [-1, 576, 32, 25]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 32, 25]           1,152\n",
            "           ReLU6-105          [-1, 576, 32, 25]               0\n",
            "          Conv2d-106           [-1, 96, 32, 25]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 32, 25]             192\n",
            "InvertedResidual-108           [-1, 96, 32, 25]               0\n",
            "          Conv2d-109          [-1, 576, 32, 25]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 32, 25]           1,152\n",
            "           ReLU6-111          [-1, 576, 32, 25]               0\n",
            "          Conv2d-112          [-1, 576, 32, 25]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 32, 25]           1,152\n",
            "           ReLU6-114          [-1, 576, 32, 25]               0\n",
            "          Conv2d-115           [-1, 96, 32, 25]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 32, 25]             192\n",
            "InvertedResidual-117           [-1, 96, 32, 25]               0\n",
            "          Conv2d-118          [-1, 576, 32, 25]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 32, 25]           1,152\n",
            "           ReLU6-120          [-1, 576, 32, 25]               0\n",
            "          Conv2d-121          [-1, 576, 16, 13]           5,184\n",
            "     BatchNorm2d-122          [-1, 576, 16, 13]           1,152\n",
            "           ReLU6-123          [-1, 576, 16, 13]               0\n",
            "          Conv2d-124          [-1, 160, 16, 13]          92,160\n",
            "     BatchNorm2d-125          [-1, 160, 16, 13]             320\n",
            "InvertedResidual-126          [-1, 160, 16, 13]               0\n",
            "          Conv2d-127          [-1, 960, 16, 13]         153,600\n",
            "     BatchNorm2d-128          [-1, 960, 16, 13]           1,920\n",
            "           ReLU6-129          [-1, 960, 16, 13]               0\n",
            "          Conv2d-130          [-1, 960, 16, 13]           8,640\n",
            "     BatchNorm2d-131          [-1, 960, 16, 13]           1,920\n",
            "           ReLU6-132          [-1, 960, 16, 13]               0\n",
            "          Conv2d-133          [-1, 160, 16, 13]         153,600\n",
            "     BatchNorm2d-134          [-1, 160, 16, 13]             320\n",
            "InvertedResidual-135          [-1, 160, 16, 13]               0\n",
            "          Conv2d-136          [-1, 960, 16, 13]         153,600\n",
            "     BatchNorm2d-137          [-1, 960, 16, 13]           1,920\n",
            "           ReLU6-138          [-1, 960, 16, 13]               0\n",
            "          Conv2d-139          [-1, 960, 16, 13]           8,640\n",
            "     BatchNorm2d-140          [-1, 960, 16, 13]           1,920\n",
            "           ReLU6-141          [-1, 960, 16, 13]               0\n",
            "          Conv2d-142          [-1, 160, 16, 13]         153,600\n",
            "     BatchNorm2d-143          [-1, 160, 16, 13]             320\n",
            "InvertedResidual-144          [-1, 160, 16, 13]               0\n",
            "          Conv2d-145          [-1, 960, 16, 13]         153,600\n",
            "     BatchNorm2d-146          [-1, 960, 16, 13]           1,920\n",
            "           ReLU6-147          [-1, 960, 16, 13]               0\n",
            "          Conv2d-148          [-1, 960, 16, 13]           8,640\n",
            "     BatchNorm2d-149          [-1, 960, 16, 13]           1,920\n",
            "           ReLU6-150          [-1, 960, 16, 13]               0\n",
            "          Conv2d-151          [-1, 320, 16, 13]         307,200\n",
            "     BatchNorm2d-152          [-1, 320, 16, 13]             640\n",
            "InvertedResidual-153          [-1, 320, 16, 13]               0\n",
            "          Conv2d-154         [-1, 1280, 16, 13]         409,600\n",
            "     BatchNorm2d-155         [-1, 1280, 16, 13]           2,560\n",
            "           ReLU6-156         [-1, 1280, 16, 13]               0\n",
            "         Dropout-157                 [-1, 1280]               0\n",
            "          Linear-158                   [-1, 48]          61,488\n",
            "================================================================\n",
            "Total params: 2,285,360\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,285,360\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.20\n",
            "Forward/backward pass size (MB): 601.54\n",
            "Params size (MB): 8.72\n",
            "Estimated Total Size (MB): 612.46\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w621NUSoifHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}